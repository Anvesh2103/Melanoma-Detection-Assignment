{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "name": ""
    },
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# **Melanoma Detection Assignment**",
      "metadata": {
        "id": "rG5nqjDeXar-"
      }
    },
    {
      "cell_type": "markdown",
      "source": "**SUBMITTED BY:**\n\n**Anvesh Audichya (anveshaudi999@gmail.com)**\n",
      "metadata": {
        "id": "gE1ccK8XXsHU"
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Problem statement:** \n\nTo build a CNN based model which can accurately detect melanoma. Melanoma is a type of cancer that can be deadly if not detected early. It accounts for 75% of skin cancer deaths. A solution which can evaluate images and alert the dermatologists about the presence of melanoma has the potential to reduce a lot of manual effort needed in diagnosis.",
      "metadata": {
        "id": "yDriIbfa5lwD"
      }
    },
    {
      "cell_type": "markdown",
      "source": "# Data Reading/Data Understanding\n### Importing Skin Cancer Data\n",
      "metadata": {
        "id": "lvR7ppk77v31"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Importing all the important libraries",
      "metadata": {
        "id": "JfcpIXQZN2Rh"
      }
    },
    {
      "cell_type": "code",
      "source": "import pathlib\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nimport PIL\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential",
      "metadata": {
        "id": "WC8xCQuELWms",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "from google.colab import drive\ndrive.mount('/content/gdrive')\n\n",
      "metadata": {
        "id": "TYpVPmT5z7AP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fb2dd65-3267-4d91-9a5c-8f3acfebcec1",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "This assignment uses a dataset of about 2357 images of skin cancer types. The dataset contains 9 sub-directories in each train and test subdirectories. The 9 sub-directories contains the images of 9 skin cancer types respectively.",
      "metadata": {
        "id": "RpUsRQwOOL72"
      }
    },
    {
      "cell_type": "code",
      "source": "# Defining the path for train and test images\n## Todo: Update the paths of the train and test dataset\ndata_dir_train = pathlib.Path(\"/content/drive/MyDrive/Colab Notebooks/Skin cancer/Train\")\ndata_dir_test = pathlib.Path('/content/drive/MyDrive/Colab Notebooks/Skin cancer/Test')",
      "metadata": {
        "id": "D57L-ovIKtI4",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Print the size of train and test data\nimage_count_train = len(list(data_dir_train.glob('*/*.jpg')))\nprint(image_count_train)\nimage_count_test = len(list(data_dir_test.glob('*/*.jpg')))\nprint(image_count_test)",
      "metadata": {
        "id": "DqksN1w5Fu-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d70242f-82c3-494f-c517-c6b395eb9e52",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## **II. Dataset Creation & visualization** ",
      "metadata": {
        "id": "UhNLIVL7aQG_"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Load using keras.preprocessing\n\nLet's load these images off disk using the helpful image_dataset_from_directory utility.",
      "metadata": {
        "id": "O8HkfW3jPJun"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Create a dataset\n\nDefine some parameters for the loader:",
      "metadata": {
        "id": "cDBKZG3jPcMc"
      }
    },
    {
      "cell_type": "code",
      "source": "batch_size = 32\nimg_height = 180\nimg_width = 180",
      "metadata": {
        "id": "VLfcXcZ9LjGv",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Use 80% of the images for training, and 20% for validation.",
      "metadata": {
        "id": "Y5f5y43GPog1"
      }
    },
    {
      "cell_type": "code",
      "source": "## Write your train dataset here\n## Note use seed=123 while creating your dataset using tf.keras.preprocessing.image_dataset_from_directory\n## Note, make sure your resize your images to the size img_height*img_width, while writting the dataset\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir_train,\n    seed=123,\n    validation_split= 0.2,\n    subset= 'training',\n    image_size=(img_height,img_width),\n    batch_size = batch_size\n)",
      "metadata": {
        "id": "G1BWmDzr7w-5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "301de740-7e0e-4161-e01c-eee173349d76",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "## Write your validation dataset here\n## Note use seed=123 while creating your dataset using tf.keras.preprocessing.image_dataset_from_directory\n## Note, make sure your resize your images to the size img_height*img_width, while writting the dataset\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir_train,\n    seed=123,\n    validation_split= 0.2,\n    subset= 'validation',\n    image_size=(img_height,img_width),\n    batch_size = batch_size\n)",
      "metadata": {
        "id": "LYch6-SR-i2g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52ac2ba9-9a18-4649-f247-56bbcbf5f047",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# List out all the classes of skin cancer and store them in a list. \n# You can find the class names in the class_names attribute on these datasets. \n# These correspond to the directory names in alphabetical order.\nclass_names = train_ds.class_names\nprint(class_names)",
      "metadata": {
        "id": "Bk0RV7G7-nad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84d8e086-afc6-4abe-aa53-c51ff8a8762a",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Visualize the data\n#### Todo, create a code to visualize one instance of all the nine classes present in the dataset",
      "metadata": {
        "id": "jbsm5oYiQH_b"
      }
    },
    {
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\n\n### your code goes here, you can use training or validation data to visualize\nplt.figure(figsize=(15,15))\nfor i in range(9): \n  plt.subplot(3, 3, i + 1)\n  image = plt.imread(str(list(data_dir_train.glob(class_names[i]+'/*.jpg'))[1]))\n  plt.title(class_names[i])\n  plt.imshow(image)",
      "metadata": {
        "id": "tKILZ48I-q1k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "outputId": "76376d5e-1fa0-459a-f4b2-6b9dd0b7eea2",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "The `image_batch` is a tensor of the shape `(32, 180, 180, 3)`. This is a batch of 32 images of shape `180x180x3` (the last dimension refers to color channels RGB). The `label_batch` is a tensor of the shape `(32,)`, these are corresponding labels to the 32 images.",
      "metadata": {
        "id": "8cAZPYaeQjQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": "`Dataset.cache()` keeps the images in memory after they're loaded off disk during the first epoch.\n\n`Dataset.prefetch()` overlaps data preprocessing and model execution while training.",
      "metadata": {
        "id": "jzVXBHiyQ7_I"
      }
    },
    {
      "cell_type": "code",
      "source": "AUTOTUNE = tf.data.experimental.AUTOTUNE\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)",
      "metadata": {
        "id": "7wZlKRBEGNtU",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## III. Model Building",
      "metadata": {
        "id": "ThXrngslbsFx"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Create the model\n#### Todo: Create a CNN model, which can accurately detect 9 classes present in the dataset. Use ```layers.experimental.preprocessing.Rescaling``` to normalize pixel values between (0,1). The RGB channel values are in the `[0, 255]` range. This is not ideal for a neural network. Here, it is good to standardize values to be in the `[0, 1]`",
      "metadata": {
        "id": "1JEAF6-sRyz8"
      }
    },
    {
      "cell_type": "code",
      "source": "### Your code goes here\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nnum_classes = 9\nmodel = Sequential([\n                    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width,3))\n])\n\n#First Convulation layer\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu', input_shape = (180, 180, 32)))\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\n#Second Convulation Layer\nmodel.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\n#Third Convulation Layer\nmodel.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', \n                 activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\n# flatten and put a fully connected Softmax layer\nmodel.add(Flatten())\nmodel.add(Dense(num_classes, activation = \"softmax\"))",
      "metadata": {
        "id": "PrxpvyOqCj50",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Compile the model\nChoose an appropirate optimiser and loss function for model training ",
      "metadata": {
        "id": "SDKzJmHwSCtt"
      }
    },
    {
      "cell_type": "code",
      "source": "### Todo, choose an appropirate optimiser and loss function\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])",
      "metadata": {
        "id": "XB8wKtiPGe1j",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# View the summary of all layers\nmodel.summary()",
      "metadata": {
        "id": "_ZGWN4MZGhtJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f39fa391-8de2-480c-c078-c1b7d7fa3879",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Train the model",
      "metadata": {
        "id": "ljD_83rwSl5O"
      }
    },
    {
      "cell_type": "code",
      "source": "epochs = 20\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs\n)",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kkfw2rJXGlYC",
        "outputId": "2fdc6f97-d4ff-4f10-d9e5-2c577e10b667",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Visualizing training results",
      "metadata": {
        "id": "w3679V8OShSE"
      }
    },
    {
      "cell_type": "code",
      "source": "acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()",
      "metadata": {
        "id": "R1xkgk5nGubz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "outputId": "04aaaa52-8e58-45cb-8e6e-a38031bd1471",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### Todo: Write your findings after the model fit, see if there is an evidence of model overfit or underfit",
      "metadata": {
        "id": "JvPphJYuSZhK"
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Finding on the first base model**\n\n- The model seems to be overfitting because we can also see **Huge difference in loss functions** in training & validation sets.\n\n- Thus, model seems to **Overfit** as there is a **huge gap** between **Training and Validation accuracy**",
      "metadata": {
        "id": "cBG60WfRjGNX"
      }
    },
    {
      "cell_type": "markdown",
      "source": "## **Rebuilding the Model with some Augmentation Strategies**",
      "metadata": {
        "id": "kqQwwTsJjOsB"
      }
    },
    {
      "cell_type": "markdown",
      "source": "Let's use some Data augumentation strategy from tensorflow to preprocess image:\n\n- RandomFlip\n- RandomRotation\n- RandomZoom",
      "metadata": {
        "id": "xU5ca7kPlPQh"
      }
    },
    {
      "cell_type": "code",
      "source": "# Todo, after you have analysed the model fit history for presence of underfit or overfit, choose an appropriate data augumentation strategy. \n# Your code goes here\ndata_augument = keras.Sequential([\n    layers.experimental.preprocessing.RandomFlip(mode=\"horizontal_and_vertical\",input_shape=(img_height,img_width,3)),\n    layers.experimental.preprocessing.RandomRotation(0.2, fill_mode='reflect'),\n    layers.experimental.preprocessing.RandomZoom(height_factor=(0.2, 0.3), width_factor=(0.2, 0.3), fill_mode='reflect')\n])\n",
      "metadata": {
        "id": "22hljAl6GykA",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Todo, visualize how your augmentation strategy works for one instance of training image.\n# Your code goes here\nplt.figure(figsize=(12, 12))\nfor images, labels in train_ds.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(data_augument(images)[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[labels[i]])\n        plt.axis(\"off\")",
      "metadata": {
        "id": "XEjPWh8GG0C7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "outputId": "70a9d1f5-3fce-48c2-b951-0d20f31bc98e",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## Create the model, compile and train the model\n",
      "metadata": {
        "id": "XhKDHlUdTuSX"
      }
    },
    {
      "cell_type": "code",
      "source": "## You can use Dropout layer if there is an evidence of overfitting in your findings\n\n## Your code goes here\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nnum_classes = 9\ninput_shape = (img_height, img_width, 3);\nmodel = Sequential()\n\n# Add augmented layers\nmodel.add(data_augument)\nmodel.add(layers.Rescaling(scale=1./255, input_shape=input_shape))\n\n#First Convulation layer\nmodel.add(layers.Conv2D(32,kernel_size=(3,3),activation='relu', padding='same'))\n#model.add(layers.BatchNormalization())\nmodel.add(layers.Conv2D(32,kernel_size=(3,3),activation='relu'))\n#model.add(layers.BatchNormalization())\nmodel.add(layers.MaxPool2D(pool_size=(2,2)))\n#model.add(layers.Dropout(0.25))\n\n#Second Convulation Layer\nmodel.add(layers.Conv2D(64,kernel_size=(3,3),activation='relu', padding='same'))\n#model.add(layers.BatchNormalization())\nmodel.add(layers.Conv2D(64,kernel_size=(3,3),activation='relu'))\n#model.add(layers.BatchNormalization())\nmodel.add(layers.MaxPool2D(pool_size=(2,2)))\nmodel.add(layers.Dropout(0.25))\n\n# flatten and put a fully connected layer\nmodel.add(layers.Flatten())\n# model.add(layers.Dense(128))\n# model.add(layers.Activation('relu'))\n# model.add(layers.Dropout(0.25))\n\n# softmax layer\nmodel.add(layers.Dense(len(class_names), activation='softmax'))\n\n# model summary\nmodel.summary()",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGidrRcalhdZ",
        "outputId": "671dfdb3-6422-4e56-c5c0-2e2053b9ecbf",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Compiling the model",
      "metadata": {
        "id": "FfUWFp96UIAN"
      }
    },
    {
      "cell_type": "code",
      "source": "## Your code goes here\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])",
      "metadata": {
        "id": "_-7yTm8IG8zR",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Training the model",
      "metadata": {
        "id": "kC-D_RWOURp6"
      }
    },
    {
      "cell_type": "code",
      "source": "## Your code goes here, note: train your model for 20 epochs\nepochs = 20\nhistory = model.fit(train_ds,validation_data=val_ds, epochs=epochs)",
      "metadata": {
        "id": "UcPfkUASHBf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "442eb749-c44b-456d-9dde-b2999ae40fb5",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### Visualizing the results",
      "metadata": {
        "id": "IhNOKtSyUYzC"
      }
    },
    {
      "cell_type": "code",
      "source": "acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()",
      "metadata": {
        "id": "vjN_F4QxHIsh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "outputId": "8d2771a6-49d0-4351-f451-13018ab86c5f",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### Todo: Write your findings after the model fit, see if there is an evidence of model overfit or underfit. Do you think there is some improvement now as compared to the previous model run?",
      "metadata": {
        "id": "0-AUR_b7UcaK"
      }
    },
    {
      "cell_type": "markdown",
      "source": "**Insights from Second Model:**\n\n- 1.1 The **second model After Augmentation is Very much better** than the first one wrt to the Training & Validation Accuracy **Improvement!**\n- 1.2 Infact, the **overfitting problem is also resolved Comparatively** to **high extent** due to data Augmentation.  \n- 1.3 We can **increase the epochs** to increase the accuracy & overall performance.",
      "metadata": {
        "id": "agwKFiT9nXHO"
      }
    },
    {
      "cell_type": "markdown",
      "source": "# **Examining Class distribution** ",
      "metadata": {
        "id": "-ePk5MAGnxTQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": "## **Find the distribution of classes in the training dataset.** \n#### **Context:** Many times real life datasets can have class imbalance, one class can have proportionately higher number of samples compared to the others. Class imbalance can have a detrimental effect on the final model quality. Hence as a sanity check it becomes important to check what is the distribution of classes in the data.",
      "metadata": {
        "id": "7TdDi4u-VTkW"
      }
    },
    {
      "cell_type": "code",
      "source": "## Your code goes here.\npath_list=[]\nlesion_list=[]\nfor i in class_names:\n      \n    for j in data_dir_train.glob(i+'/*.jpg'):\n        path_list.append(str(j))\n        lesion_list.append(i)\ndataframe_dict_original = dict(zip(path_list, lesion_list))\noriginal_df = pd.DataFrame(list(dataframe_dict_original.items()),columns = ['Path','Label'])\noriginal_df",
      "metadata": {
        "id": "HAhwYgtTQRzq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "ef5cdd17-88e3-4c83-ac66-11cceb2fd593",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Create a dataframe with class name and count of image in that class\nfrom sklearn.preprocessing import LabelEncoder\nfrom collections import Counter\n# split into input and output elements\nX, y = original_df['Path'], original_df['Label']\n# label encode the target variable\ny = LabelEncoder().fit_transform(y)\n# summarize distribution\ncounter = Counter(y)\nfor k,v in counter.items():\n\tper = v / len(y) * 100\n\tprint('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n# plot the distribution\nplt.bar(counter.keys(), counter.values())\nplt.show()",
      "metadata": {
        "id": "vl9LrQeLpNhA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "7dadd274-ea61-4c22-94d7-89ff205369b1",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#  Examining the current class distribution in the training dataset \ncount=[]\nfor n in class_names:\n    count.append(len(list(data_dir_train.glob(n+'/*.jpg'))))\nplt.figure(figsize=(26,15))\nplt.bar(class_names,count)\nplt.show()",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "id": "izaGomTvs_EC",
        "outputId": "add0d61a-7b11-4e44-d006-0db021689ff3",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### **Findings/Insights of Class Distribution:**   \n\n#### - **Which class has the least number of samples?**\nAnswer-1 :-     \nWe can see that **\"seborrheic keratosis\"** has the least number of samples.\n\n\n#### - **Which classes dominate the data in terms proportionate number of samples?**\nAnswer-2:-       \nA) We can observe from plot that **\"melanoma\" and \"pigmented benign keratosis\"** have proportionate number of samples in them.   \nB)  Similar type of proportionate number of samples can be seen in **\"basal cell carcinoma\" and \"nevus\".**\n",
      "metadata": {
        "id": "4csQL1dvO0b2"
      }
    },
    {
      "cell_type": "code",
      "source": "class_names",
      "metadata": {
        "id": "Kxn61O3Wo8e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9b9a20c-cbfa-4f0d-e23a-3da985625bce",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "**Insight:**\n- `**seborrheic keratosis**` has the **least number** of **samples (77)**\n- `**pigmented benigh keratosis** ` has the **most number of samples (462)**\n\n\n***We can see the imbalance in class distribution of the dataset***",
      "metadata": {
        "id": "8cSP-xcZuiQZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": "# **Handling class imbalances**",
      "metadata": {
        "id": "bNYtaju4uyOO"
      }
    },
    {
      "cell_type": "markdown",
      "source": "#### **Todo:** Rectify the class imbalance\n#### **Context:** You can use a python package known as `Augmentor` (https://augmentor.readthedocs.io/en/master/) to add more samples across all classes so that none of the classes have very few samples.",
      "metadata": {
        "id": "Hb-stKyHPf8v"
      }
    },
    {
      "cell_type": "code",
      "source": "!pip install Augmentor",
      "metadata": {
        "id": "ItAg4rU-SzJh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4799f0e-71b5-4146-8f14-186b22efa0cb",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "To use `Augmentor`, the following general procedure is followed:\n\n1. Instantiate a `Pipeline` object pointing to a directory containing your initial image data set.<br>\n2. Define a number of operations to perform on this data set using your `Pipeline` object.<br>\n3. Execute these operations by calling the `Pipeline’s` `sample()` method.\n",
      "metadata": {
        "id": "BZKzTe3zWL4O"
      }
    },
    {
      "cell_type": "code",
      "source": "path_to_training_dataset=\"/content/drive/MyDrive/Colab Notebooks/Skin cancer/Train/\"\nimport Augmentor\nfor i in class_names:\n    p = Augmentor.Pipeline(path_to_training_dataset + i)\n    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n    p.sample(500) ## We are adding 500 samples per class to make sure that none of the classes are sparse.",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Egt9EHjR-Dd",
        "outputId": "3af4130b-db55-4211-8b03-60c3d06e14e7",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Augmentor has stored the augmented images in the output sub-directory of each of the sub-directories of skin cancer types.. Lets take a look at total count of augmented images.",
      "metadata": {
        "id": "CcBIFZGbWuFa"
      }
    },
    {
      "cell_type": "code",
      "source": "from glob import glob\nimage_count_train = len(list(data_dir_train.glob('*/output/*.jpg')))\nprint(image_count_train)",
      "metadata": {
        "id": "jxWcMqZhdRWz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7951b83-e715-4696-f5a5-118dec3e8e08",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "for i in class_names:\n      \n    for j in data_dir_train.glob(i+'/*.jpg'):\n        path_list.append(str(j))\n        lesion_list.append(i)\ndataframe_dict_original = dict(zip(path_list, lesion_list))\nnew_df = pd.DataFrame(list(dataframe_dict_original.items()),columns = ['Path','Label'])\nnew_df",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "rfnkYpcCu3_6",
        "outputId": "26e393a2-2962-44a3-88bf-78ee8a1e6e89",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "new_df.shape",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPmUm16lxH4W",
        "outputId": "28e2a0f4-132d-4ed7-d820-80fb064b2580",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "original_df['Label'].value_counts()",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcVe8ek4vORo",
        "outputId": "bbc27481-c27c-46ad-bf5e-992eb6218f43",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### **Lets see the distribution of augmented data after adding new images to the original training data.**   ",
      "metadata": {
        "id": "IJ5KarKq4kWJ"
      }
    },
    {
      "cell_type": "code",
      "source": "path_list_new = [x for x in glob(os.path.join(data_dir_train, '*','output', '*.jpg'))]\npath_list_new",
      "metadata": {
        "id": "6tODrYIY2nxJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48ccd4b9-414f-4c31-e615-cc837d56a074",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "lesion_list_new = [os.path.basename(os.path.dirname(os.path.dirname(y))) for y in glob(os.path.join(data_dir_train, '*','output', '*.jpg'))]\nlesion_list_new",
      "metadata": {
        "id": "nZvVdF7g3E1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b0f9804-3560-43a6-e8e1-9df36fd51a3f",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "dataframe_dict_new = dict(zip(path_list_new, lesion_list_new))",
      "metadata": {
        "id": "okcqVFAA2nxK",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "df2 = pd.DataFrame(list(dataframe_dict_new.items()),columns = ['Path','Label'])\nnew_df = original_df.append(df2)",
      "metadata": {
        "id": "njzBxTNT2nxK",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "new_df['Label'].value_counts()",
      "metadata": {
        "id": "5j45rmxd2nxK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70b0d73d-70cb-4412-a76b-fc025e09b2a5",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "**Insight:**   \nSo, now we have **added 500 images to all the classes to maintain some class balance**. We can add more images as we want to improve training process.",
      "metadata": {
        "id": "9NirFBvGPmgI"
      }
    },
    {
      "cell_type": "markdown",
      "source": "# **Model Building & training on the rectified class imbalance data**   ",
      "metadata": {
        "id": "7FG6nr_Rxy2f"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### **Train the model on the data created using Augmentor** ",
      "metadata": {
        "id": "9EnspeMbRWNs"
      }
    },
    {
      "cell_type": "code",
      "source": "batch_size = 32\nimg_height = 180\nimg_width = 180",
      "metadata": {
        "id": "hFcj1XgndRWz",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### **Create a training dataset**    ",
      "metadata": {
        "id": "0haOU11Ey8ey"
      }
    },
    {
      "cell_type": "code",
      "source": "data_dir_train=\"/content/drive/MyDrive/Colab Notebooks/Skin cancer/Train\"\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  data_dir_train,\n  seed=123,\n  validation_split = 0.2,\n  subset = \"training\",\n  image_size=(img_height, img_width),\n  batch_size=batch_size)",
      "metadata": {
        "id": "H4ZY11judRWz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de24cf90-85db-4291-d466-2f34cc98f392",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "###  **Create a validation dataset**   ",
      "metadata": {
        "id": "mwNJVDuBP5kf"
      }
    },
    {
      "cell_type": "code",
      "source": "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  data_dir_train,\n  seed=123,\n  validation_split = 0.2,\n  subset = \"validation\",\n  image_size=(img_height, img_width),\n  batch_size=batch_size)",
      "metadata": {
        "id": "TX191d_3dRW0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96169feb-658f-4273-8495-72053f1b40e9",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## **Model Building**      ",
      "metadata": {
        "id": "EtcpxPlKy4g3"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Create your model (make sure to include normalization)",
      "metadata": {
        "id": "JaoWeOEpVjqH"
      }
    },
    {
      "cell_type": "markdown",
      "source": "#### **MODEL - 1**",
      "metadata": {
        "id": "bPIlFYMy9Mx2"
      }
    },
    {
      "cell_type": "code",
      "source": "## your code goes here\nimport pathlib\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nimport PIL\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.regularizers import l2\n\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nnum_classes = 9\nmodel = Sequential([ \n                    layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width,3))\n      \n])\n\n#First Convolution layer\nmodel.add(layers.Conv2D(32,kernel_size=(3,3),activation='relu', padding='same'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Conv2D(32,kernel_size=(3,3),activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPool2D(pool_size=(2,2)))\nmodel.add(layers.Dropout(0.25))\n\n#Second Convulation Layer\nmodel.add(layers.Conv2D(64,kernel_size=(3,3),activation='relu', padding='same'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Conv2D(64,kernel_size=(3,3),activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPool2D(pool_size=(2,2)))\nmodel.add(layers.Dropout(0.25))\n\n#Third Convulation Layer\nmodel.add(layers.Conv2D(128,kernel_size=(3,3),activation='relu', padding='same'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Conv2D(128,kernel_size=(3,3),activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPool2D(pool_size=(2,2)))\nmodel.add(layers.Dropout(0.25))\n\n# flatten and put a fully connected layer\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, kernel_regularizer=l2(0.01)))\nmodel.add(layers.Activation('relu'))\nmodel.add(layers.Dropout(0.5))\n\n# softmax layer\nmodel.add(layers.Dense(len(class_names), activation='softmax'))",
      "metadata": {
        "id": "Ch0MuKvFVr7O",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "## **Compile your model (Choose optimizer and loss function appropriately)**  ",
      "metadata": {
        "id": "Bu5N9LxkVx1B"
      }
    },
    {
      "cell_type": "code",
      "source": "## your code goes here\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])",
      "metadata": {
        "id": "H47GWmLbdRW1",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "###  **Training Model**  ",
      "metadata": {
        "id": "9gS-Y1bJV7uy"
      }
    },
    {
      "cell_type": "code",
      "source": "epochs = 30\n## Your code goes here, use 30 epochs.\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs\n)",
      "metadata": {
        "id": "fcV6OdI4dRW1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee9aa205-3eb8-427d-d3a0-70c3cdf67a28",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### **Todo:**  Visualize the model results",
      "metadata": {
        "id": "iuvfCTsBWLMp"
      }
    },
    {
      "cell_type": "code",
      "source": "acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()",
      "metadata": {
        "id": "lCTXwfkTdRW1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "outputId": "e4420dad-bca4-4359-db7f-33d8182bca33",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### **MODEL - 2**",
      "metadata": {
        "id": "vP6t5ud-9cFs"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### **Create, compile and train the model**  ",
      "metadata": {
        "id": "_dDtjLG59qzA"
      }
    },
    {
      "cell_type": "code",
      "source": "from tensorflow.keras.regularizers import l2\n\ninput_shape = (img_height, img_width, 3);\n# model\nmodel = Sequential()\n\nmodel.add(layers.Rescaling(scale=1./255, input_shape=input_shape))\n\n#First Convulation layer\nmodel.add(layers.Conv2D(32,kernel_size=(3,3),activation='relu', padding='same'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Conv2D(32,kernel_size=(3,3),activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPool2D(pool_size=(2,2)))\nmodel.add(layers.Dropout(0.25))\n\n#Second Convulation Layer\nmodel.add(layers.Conv2D(64,kernel_size=(3,3),activation='relu', padding='same'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Conv2D(64,kernel_size=(3,3),activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPool2D(pool_size=(2,2)))\nmodel.add(layers.Dropout(0.25))\n\n#Third Convulation Layer\nmodel.add(layers.Conv2D(128,kernel_size=(3,3),activation='relu', padding='same'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.Conv2D(128,kernel_size=(3,3),activation='relu'))\nmodel.add(layers.BatchNormalization())\nmodel.add(layers.MaxPool2D(pool_size=(2,2)))\nmodel.add(layers.Dropout(0.25))\n\n# flatten and put a fully connected layer\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, kernel_regularizer=l2(0.01)))\nmodel.add(layers.Activation('relu'))\nmodel.add(layers.Dropout(0.5))\n\n# softmax layer\nmodel.add(layers.Dense(len(class_names), activation='softmax'))\n\n# model summary\nmodel.summary()\n\n# Compile and train model\nmodel.compile(loss='sparse_categorical_crossentropy',\n              optimizer='sgd',\n              metrics=['accuracy'])\n\n#Training for 50 epochs\nepochs = 50\nhistory = model.fit(train_ds, validation_data=val_ds, epochs=epochs)",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDvjuqKU9d_u",
        "outputId": "db0ec349-b666-4f66-d8bd-8b8b8666cf8b",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "### **Visualize the Model Results:**",
      "metadata": {
        "id": "Ib9g36oQKB35"
      }
    },
    {
      "cell_type": "code",
      "source": "acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(12, 12))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "id": "_te-VUYX9eDS",
        "outputId": "f920177b-c895-44e3-de0a-b46ec3ddc842",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "#### **Todo:**  Analyze your results here. Did you get rid of underfitting/overfitting? Did class rebalance help?\n\n",
      "metadata": {
        "id": "Way4lakC4_p0"
      }
    },
    {
      "cell_type": "markdown",
      "source": "## **Insights:**  \n\n1.  After **20 epochs**, the training accuracy is 60% and validation accuracy is 50%, which is better than the first model\n2.  After **30 epochs** the training accuracy is 75% and validation accuracy is 70% with least overfitting.\n3.  After **50 epochs** the **Training Accuracy is 94%** and **Validation Accuracy is 83%**, the model Performance drastically Improved with **No overfitting**\n",
      "metadata": {
        "id": "KmxusE_6Br8c"
      }
    },
    {
      "cell_type": "markdown",
      "source": "## **Inferences/Observations:**    \n\n* By using **Augmentor library, Data Imbalance Issue is Resolved** & **Overall Accuracy** on training data has **Increased**.\n\n* By adding more CNN layers with **Batch Normalization** & also adding **dropouts**, the **Problem of Overfitting is completely Resolved** now.\n\n* By **tuning the hyperparameter Model**, wrt no of epochs, using appropriate optimizer & loss function, augmentation, class imbalance handling thereby further Drastic Improvement wrt **Increased Performance** was observed.\n\n* **Class Rebalance Really Helped** with **Good Model Performance & Accuracy with No Overfitting** shows evidence issues are resolved.",
      "metadata": {
        "id": "FsTGx-ZqCOus"
      }
    }
  ]
}